{
  
    
        "post0": {
            "title": "cufflinks docs",
            "content": "Help on method _iplot in module cufflinks.plotlytools: _iplot( kind=&#39;scatter&#39;, data=None, layout=None, filename=&#39;&#39;, sharing=None, title=&#39;&#39;, xTitle=&#39;&#39;, yTitle=&#39;&#39;, zTitle=&#39;&#39;, theme=None, colors=None, colorscale=None, fill=False, width=None, dash=&#39;solid&#39;, mode=&#39;&#39;, interpolation=&#39;linear&#39;, symbol=&#39;circle&#39;, size=12, barmode=&#39;&#39;, sortbars=False, bargap=None, bargroupgap=None, bins=None, histnorm=&#39;&#39;, histfunc=&#39;count&#39;, orientation=&#39;v&#39;, boxpoints=False, annotations=None, keys=False, bestfit=False, bestfit_colors=None, mean=False, mean_colors=None, categories=&#39;&#39;, x=&#39;&#39;, y=&#39;&#39;, z=&#39;&#39;, text=&#39;&#39;, gridcolor=None, zerolinecolor=None, margin=None, labels=None, values=None, secondary_y=&#39;&#39;, secondary_y_title=&#39;&#39;, subplots=False, shape=None, error_x=None, error_y=None, error_type=&#39;data&#39;, locations=None, lon=None, lat=None, asFrame=False, asDates=False, asFigure=False, asImage=False, dimensions=None, asPlot=False, asUrl=False, online=None, **kwargs ) method of pandas.core.frame.DataFrame instance Returns a plotly chart either as inline chart, image of Figure object Parameters: -- kind : string Kind of chart scatter bar box spread ratio heatmap surface histogram bubble bubble3d scatter3d scattergeo ohlc candle pie choroplet data : Data Plotly Data Object. If not entered then the Data object will be automatically generated from the DataFrame. layout : Layout Plotly layout Object If not entered then the Layout objet will be automatically generated from the DataFrame. filename : string Filename to be saved as in plotly account sharing : string Sets the sharing level permission public - anyone can see this chart private - only you can see this chart secret - only people with the link can see the chart title : string Chart Title xTitle : string X Axis Title yTitle : string Y Axis Title zTitle : string zTitle : string Z Axis Title Applicable only for 3d charts theme : string Layout Theme solar pearl white see cufflinks.getThemes() for all available themes colors : dict, list or string {key:color} to specify the color for each column [colors] to use the colors in the defined order colorscale : string Color scale name If the color name is preceded by a minus (-) then the scale is inversed Only valid if &#39;colors&#39; is null See cufflinks.colors.scales() for available scales fill : bool Filled Traces width : dict, list or int int : applies to all traces list : applies to each trace in the order specified dict: {column:value} for each column in the dataframe Line width dash : dict, list or string string : applies to all traces list : applies to each trace in the order specified dict: {column:value} for each column in the dataframe Drawing style of lines solid dash dashdot dot mode : dict, list or string string : applies to all traces list : applies to each trace in the order specified dict: {column:value} for each column in the dataframe Plotting mode for scatter trace lines markers lines+markers lines+text markers+text lines+markers+text interpolation : dict, list, or string string : applies to all traces list : applies to each trace in the order specified dict: {column:value} for each column in the dataframe Positioning of the connecting lines linear spline vhv hvh vh hv symbol : dict, list or string string : applies to all traces list : applies to each trace in the order specified dict: {column:value} for each column in the dataframe The symbol that is drawn on the plot for each marker Valid only when mode includes markers circle circle-dot diamond square and many more...(see plotly.validators.scatter.marker.SymbolValidator.values) size : string or int Size of marker Valid only if marker in mode barmode : string Mode when displaying bars group stack overlay * Only valid when kind=&#39;bar&#39; sortbars : bool Sort bars in descending order * Only valid when kind=&#39;bar&#39; bargap : float Sets the gap between bars [0,1) * Only valid when kind is &#39;histogram&#39; or &#39;bar&#39; bargroupgap : float Set the gap between groups [0,1) * Only valid when kind is &#39;histogram&#39; or &#39;bar&#39; bins : int or tuple if int: Specifies the number of bins if tuple: (start, end, size) start : starting value end: end value size: bin size * Only valid when kind=&#39;histogram&#39; histnorm : string &#39;&#39; (frequency) percent probability density probability density Sets the type of normalization for an histogram trace. By default the height of each bar displays the frequency of occurrence, i.e., the number of times this value was found in the corresponding bin. If set to &#39;percent&#39;, the height of each bar displays the percentage of total occurrences found within the corresponding bin. If set to &#39;probability&#39;, the height of each bar displays the probability that an event will fall into the corresponding bin. If set to &#39;density&#39;, the height of each bar is equal to the number of occurrences in a bin divided by the size of the bin interval such that summing the area of all bins will yield the total number of occurrences. If set to &#39;probability density&#39;, the height of each bar is equal to the number of probability that an event will fall into the corresponding bin divided by the size of the bin interval such that summing the area of all bins will yield 1. * Only valid when kind=&#39;histogram&#39; histfunc : string count sum avg min max Sets the binning function used for an histogram trace. * Only valid when kind=&#39;histogram&#39; orientation : string h v Sets the orientation of the bars. If set to &#39;v&#39;, the length of each | bar will run vertically. If set to &#39;h&#39;, the length of each bar will | run horizontally * Only valid when kind is &#39;histogram&#39;,&#39;bar&#39; or &#39;box&#39; boxpoints : string Displays data points in a box plot outliers all suspectedoutliers False annotations : dictionary Dictionary of annotations {x_point : text} keys : list of columns List of columns to chart. Also can be used for custom sorting. bestfit : boolean or list If True then a best fit line will be generated for all columns. If list then a best fit line will be generated for each key on the list. bestfit_colors : list or dict {key:color} to specify the color for each column [colors] to use the colors in the defined order categories : string Name of the column that contains the categories x : string Name of the column that contains the x axis values y : string Name of the column that contains the y axis values z : string Name of the column that contains the z axis values text : string Name of the column that contains the text values gridcolor : string Grid color zerolinecolor : string Zero line color margin : dict or tuple Dictionary (l,r,b,t) or Tuple containing the left, right, bottom and top margins labels : string Name of the column that contains the labels. * Only valid when kind=&#39;pie&#39; values : string Name of the column that contains the values. * Only valid when kind=&#39;pie&#39; secondary_y : string or list(string) Name(s) of the column to be charted on the right hand side axis secondary_y_title : string Title of the secondary axis subplots : bool If true then each trace is placed in subplot layout shape : (rows,cols) Tuple indicating the size of rows and columns If omitted then the layout is automatically set * Only valid when subplots=True error_x : int or float or [int or float] error values for the x axis error_y : int or float or [int or float] error values for the y axis error_type : string type of error bars &#39;data&#39; &#39;constant&#39; &#39;percent&#39; &#39;sqrt&#39; &#39;continuous&#39; &#39;continuous_percent&#39; asFrame : bool If true then the data component of Figure will be of Pandas form (Series) otherwise they will be index values asDates : bool If true it truncates times from a DatetimeIndex asFigure : bool If True returns plotly Figure asImage : bool If True it returns an Image (png) In ONLINE mode: Image file is saved in the working directory Accepts: filename dimensions scale display_image In OFFLINE mode: Image file is downloaded (downloads folder) and a regular plotly chart is displayed in Jupyter Accepts: filename dimensions dimensions : tuple(int,int) Dimensions for image / chart (width,height) asPlot : bool If True the chart opens in browser asUrl : bool If True the chart url/path is returned. No chart is displayed. If Online : the URL is returned If Offline : the local path is returned online : bool If True then the chart/image is rendered on the server even when running in offline mode. Other Kwargs ============ Line, Scatter connectgaps : bool If True, empty values are connected Pie charts sort : bool If True it sorts the labels by value pull : float [0-1] Pulls the slices from the centre hole : float [0-1] Sets the size of the inner hole linecolor : string Sets the color for the contour line of the slices linewidth : string Sets the width for the contour line of the slices textcolor : string Sets the color for the text in the slices textposition : string Sets the position of the legends for each slice outside inner textinfo : string Sets the information to be displayed on the legends label percent value * or ony combination of the above using &#39;+&#39; between each item ie &#39;label+percent&#39; Histogram linecolor : string specifies the line color of the histogram Heatmap and Surface center_scale : float Centers the colorscale at a specific value Automatically sets the (zmin,zmax) values zmin : float Defines the minimum range for the z values. This affects the range for the colorscale zmax : float Defines the maximum range for the z values. This affects the range for the colorscale Error Bars error_trace : string Name of the column for which error should be plotted. If omitted then errors apply to all traces. error_values_minus : int or float or [int or float] Values corresponding to the span of the error bars below the trace coordinates error_color : string Color for error bars error_thickness : float Sets the line thickness of the error bars error_width : float Sets the width (in pixels) of the cross-bar at both ends of the error bars error_opacity : float [0,1] Opacity for the error bars Subplots horizontal_spacing : float [0,1] Space between subplot columns. vertical_spacing : float [0,1] Space between subplot rows. subplot_titles : bool If True, chart titles are plotted at the top of each subplot shared_xaxes : bool Assign shared x axes. If True, subplots in the same grid column have one common shared x-axis at the bottom of the grid. shared_yaxes : bool Assign shared y axes. If True, subplots in the same grid row have one common shared y-axis on the left-hand side of the grid. Shapes hline : float, list or dict Draws a horizontal line at the indicated y position(s) Extra parameters can be passed in the form of a dictionary (see shapes) vline : float, list or dict Draws a vertical line at the indicated x position(s) Extra parameters can be passed in the form of a dictionary (see shapes) hpsan : (y0,y1) Draws a horizontal rectangle at the indicated (y0,y1) positions. Extra parameters can be passed in the form of a dictionary (see shapes) vspan : (x0,x1) Draws a vertical rectangle at the indicated (x0,x1) positions. Extra parameters can be passed in the form of a dictionary (see shapes) shapes : dict or list(dict) List of dictionaries with the specifications of a given shape. See help(cufflinks.tools.get_shape) for more information Axis Ranges xrange : [lower_bound,upper_bound] Sets the range for the x axis yrange : [lower_bound,upper_bound] Sets the range for the y axis zrange : [lower_bound,upper_bound] Sets the range for the z axis Explicit Layout Updates layout_update : dict The layout will be modified with all the explicit values stated in the dictionary. It will not apply if layout is passed as parameter. Range Selector rangeselector : dict Defines a rangeselector object see help(cf.tools.get_range_selector) for more information Example: {&#39;steps&#39;:[&#39;1y&#39;,&#39;2 months&#39;,&#39;5 weeks&#39;,&#39;ytd&#39;,&#39;2mtd&#39;], &#39;axis&#39;:&#39;xaxis&#39;, &#39;bgcolor&#39; : (&#39;blue&#39;,.3), &#39;x&#39;: 0.2 , &#39;y&#39; : 0.9} Range Slider rangeslider : bool or dict Defines if a rangeslider is displayed If bool: True : Makes it visible if dict: Rangeslider object Example: {&#39;bgcolor&#39;:(&#39;blue&#39;,.3),&#39;autorange&#39;:True} Annotations fontcolor : str Text color for annotations fontsize : int Text size for annotations textangle : int Text angle See https://plot.ly/python/reference/#layout-annotations for a complete list of valid parameters. Exports display_image : bool If True then the image if displayed after being saved ** only valid if asImage=True scale : integer Increase the resolution of the image by `scale` amount Only valid when asImage=True .",
            "url": "https://donyum.github.io/blog/plotly/2020/04/28/plotly-cufflinks-px.html",
            "relUrl": "/plotly/2020/04/28/plotly-cufflinks-px.html",
            "date": " • Apr 28, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "fastpages最佳实践",
            "content": "支持jupyter、md、docx，分别放到_notebooks、_posts、_word文件夹下面即可，提交后github上的CI/CD会自动处理生成静态站点。 . 图片： . 有时候copied_from_nb下面的图片不会被拷贝过去。 . . pdf或其他引用文件 . plotly不支持，但是支持matplotlib和altair . 代码、output的隐藏、折叠 . hide/collapse-show/collapse-hide . 中文字体 . 高亮提示 . Note/Warnning/Important .",
            "url": "https://donyum.github.io/blog/fastpages/2020/04/19/about-fastpages.html",
            "relUrl": "/fastpages/2020/04/19/about-fastpages.html",
            "date": " • Apr 19, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "异常点检测模型实验",
            "content": "import sys import time # import logging import datetime from pathlib import Path import numpy as np import pandas as pd from pandas.tseries.offsets import * # import plotly_express as px # import cufflinks as cf from sklearn import preprocessing from tqdm import tqdm_notebook as tqdm . import cufflinks as cf cf.set_config_file(offline=True, theme=&#39;pearl&#39;) import talib as ta import plotly_express as px . &#25968;&#25454;&#21152;&#36733; . #collapse-show df = pd.read_csv(&#39;./sample_21.txt&#39;) df . . 交易时间 交易金额 转账附言 渠道 发起方id 发起方年龄 发起方所处地区 接收方ID . 0 2017-12-23 00:07:36 | 1989200 | 转账 | 普通转账 | 3655 | 22 | 广东 | 44 | . 1 2017-12-23 00:08:25 | 4802500 | - | 线下付款 | 2703 | 50 | 新疆 | 47 | . 2 2017-12-23 00:12:37 | 3254000 | - | 线上付款 | 3476 | 36 | 安徽 | 92 | . 3 2017-12-23 00:12:50 | 3458600 | - | 线下付款 | 6017 | 31 | 贵州 | 43 | . 4 2017-12-23 00:13:21 | 2085400 | 奖金 | 普通转账 | 1904 | 37 | 云南 | 18 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 20016 2018-02-28 14:07:39 | 2515300 | 上次买的xx | 跨境转账 | 304 | 23 | 美国 | 71 | . 20017 2018-02-28 14:35:16 | 4910500 | 李xx给张xx的钱 | 普通转账 | 3689 | 32 | 黑龙江 | 55 | . 20018 2018-02-28 14:40:07 | 3096400 | 李xx给张xx的钱 | 普通转账 | 320 | 35 | 上海 | 24 | . 20019 2018-02-28 14:41:10 | 3661000 | 还给你 | 普通转账 | 3909 | 42 | 上海 | 90 | . 20020 2018-02-28 14:45:10 | 3049800 | 奖金 | 跨境转账 | 2525 | 31 | 美国 | 32 | . 20021 rows × 8 columns . df.columns = [&#39;time&#39;, &#39;cash_amount&#39;, &#39;comment&#39;, &#39;channel&#39;, &#39;starter_id&#39;, &#39;starter_age&#39;, &#39;starter_area&#39;, &#39;receiver_id&#39;] df.describe() . cash_amount starter_id starter_age receiver_id . count 2.002100e+04 | 20021.000000 | 20021.000000 | 20021.000000 | . mean 2.509762e+06 | 3498.215674 | 33.934369 | 51.956895 | . std 1.446299e+06 | 2013.401076 | 9.564053 | 80.228028 | . min 1.010000e+04 | 1.000000 | 18.000000 | 1.000000 | . 25% 1.264900e+06 | 1754.000000 | 26.000000 | 26.000000 | . 50% 2.492100e+06 | 3500.000000 | 34.000000 | 51.000000 | . 75% 3.751800e+06 | 5238.000000 | 42.000000 | 76.000000 | . max 8.888800e+06 | 7000.000000 | 88.000000 | 6258.000000 | . &#25968;&#25454;&#25506;&#32034; . 这一部工作很适合用Tableau来做，使用Tableau分析的结果详见 《AliAntTest_数据探索及模型选择.pdf》。 . &#27169;&#22411;&#30340;&#36873;&#25321; . 风险监控问题的本质是分类问题，目前想到的可用模型有： . 非监督学习——聚类； . 在聚类效果上，谱聚类、DBscan的方法是非线性的，精度最优，但DBscan要探索一个阈值，灵活性低。 . 而谱聚类方法可以通过指定cluster个数来聚类，风险监控场景可以看作二分类场景，聚类个数一定是2，所以谱聚类比较贴合这个场景。 . 几种常用聚类方法的比较： . | . . 监督学习——深度学习模型； . 监督学习需要有大量标注数据，在这个场景下显然是不适合的。 . 不过阿里应该不缺这些数据，比如用户在被盗、被骗之后大概率会联系阿里，告知哪些交易非本人操作，抑或哪些交易是被骗的，这些反馈可以比较准确的帮助阿里沉淀带标签的数据。 . | 异常点检测 . 这一类算法是在风控模型里比较常用的一种方法，常用的是Isolation Forest算法。 . | . . 在这里为了照顾模型精度和开发工作量，选用两种聚类方法K-menas、谱聚类和Isolation Forest算法来构建模型。 . &#29305;&#24449;&#25552;&#21462; . 尝试从下面三个维度提取特征，并比较提取特征的优劣： . 基于事实表的特征提取 | 基于ID之间交易的特征提取 | 基于ID的特征提取Notes:其实从数据探索过程中可以发现第3种最好，但实际场景下特征维度会非常多，所以特征提取前期应该尽可能多的探索一下。 . | Notes:特征提取方法：连续值用z-score归一化处理，离散值用one-hot方法做稀疏处理。 . &#22522;&#20110;&#20107;&#23454;&#34920;&#30340;&#29305;&#24449;&#25552;&#21462; . 可用于构造特征的维度有： . 交易金额； | 交易数量； | 发起地区； | 年龄； | 渠道； | . z-score&#26631;&#20934;&#21270;: &#20132;&#26131;&#37329;&#39069;&#12289;&#24180;&#40836; . z_score_scaler = preprocessing.StandardScaler() z_score_feature = z_score_scaler.fit_transform(df[[&#39;cash_amount&#39;, &#39;starter_age&#39;]]) . features = pd.DataFrame(z_score_feature, columns=[&#39;cash_amount&#39;, &#39;starter_age&#39;]) . features . cash_amount starter_age . 0 -0.359936 | -1.247867 | . 1 1.585284 | 1.679835 | . 2 0.514594 | 0.215984 | . 3 0.656062 | -0.306820 | . 4 -0.293420 | 0.320545 | . ... ... | ... | . 20016 0.003829 | -1.143306 | . 20017 1.659959 | -0.202259 | . 20018 0.405623 | 0.111423 | . 20019 0.796009 | 0.843349 | . 20020 0.373402 | -0.306820 | . 20021 rows × 2 columns . OneHot&#8212;&#8212;&#28192;&#36947; . ch_one_hot_enc = preprocessing.OneHotEncoder() ch_one_hot_enc.fit(df[[&#39;channel&#39;]]) # enc.n_values_ . OneHotEncoder(categories=&#39;auto&#39;, drop=None, dtype=&lt;class &#39;numpy.float64&#39;&gt;, handle_unknown=&#39;error&#39;, sparse=True) . ch_one_hot_enc . OneHotEncoder(categories=&#39;auto&#39;, drop=None, dtype=&lt;class &#39;numpy.float64&#39;&gt;, handle_unknown=&#39;error&#39;, sparse=True) . res = ch_one_hot_enc.transform(df[[&#39;channel&#39;]]).toarray() . for i in range(res.shape[1]): features[f&#39;ch_{i}&#39;] = res.T[0] . features . cash_amount starter_age ch_0 ch_1 ch_2 ch_3 . 0 -0.359936 | -1.247867 | 1.0 | 1.0 | 1.0 | 1.0 | . 1 1.585284 | 1.679835 | 0.0 | 0.0 | 0.0 | 0.0 | . 2 0.514594 | 0.215984 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 0.656062 | -0.306820 | 0.0 | 0.0 | 0.0 | 0.0 | . 4 -0.293420 | 0.320545 | 1.0 | 1.0 | 1.0 | 1.0 | . ... ... | ... | ... | ... | ... | ... | . 20016 0.003829 | -1.143306 | 0.0 | 0.0 | 0.0 | 0.0 | . 20017 1.659959 | -0.202259 | 1.0 | 1.0 | 1.0 | 1.0 | . 20018 0.405623 | 0.111423 | 1.0 | 1.0 | 1.0 | 1.0 | . 20019 0.796009 | 0.843349 | 1.0 | 1.0 | 1.0 | 1.0 | . 20020 0.373402 | -0.306820 | 0.0 | 0.0 | 0.0 | 0.0 | . 20021 rows × 6 columns . OneHo&#8212;&#8212;starter_area . area_one_hot_enc = preprocessing.OneHotEncoder() area_one_hot_enc.fit(df[[&#39;starter_area&#39;]]) . OneHotEncoder(categories=&#39;auto&#39;, drop=None, dtype=&lt;class &#39;numpy.float64&#39;&gt;, handle_unknown=&#39;error&#39;, sparse=True) . area_one_hot_enc . OneHotEncoder(categories=&#39;auto&#39;, drop=None, dtype=&lt;class &#39;numpy.float64&#39;&gt;, handle_unknown=&#39;error&#39;, sparse=True) . res = area_one_hot_enc.transform(df[[&#39;starter_area&#39;]]).toarray() . for i in range(res.shape[1]): features[f&#39;area_{i}&#39;] = res.T[0] . features . cash_amount starter_age ch_0 ch_1 ch_2 ch_3 area_0 area_1 area_2 area_3 ... area_11 area_12 area_13 area_14 area_15 area_16 area_17 area_18 area_19 area_20 . 0 -0.359936 | -1.247867 | 1.0 | 1.0 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1 1.585284 | 1.679835 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 2 0.514594 | 0.215984 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 0.656062 | -0.306820 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 4 -0.293420 | 0.320545 | 1.0 | 1.0 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 20016 0.003829 | -1.143306 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 20017 1.659959 | -0.202259 | 1.0 | 1.0 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 20018 0.405623 | 0.111423 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | ... | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | . 20019 0.796009 | 0.843349 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | ... | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | . 20020 0.373402 | -0.306820 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 20021 rows × 27 columns . &#38477;&#32500;&#35266;&#23519;&#29305;&#24449;&#30340;&#26377;&#25928;&#24615; . import ipyvolume as ipv . %%time from sklearn.manifold import TSNE tsne = TSNE(n_components=3) res = tsne.fit_transform(features) . CPU times: user 12min 25s, sys: 239 ms, total: 12min 25s Wall time: 1min 33s . df_res = pd.DataFrame(index=features.index) for i in range(3): df_res[i] = res[:, i] . df_res . x y z . 0 -10.471446 | 5.430979 | 9.627109 | . 1 28.118803 | 1.658957 | -5.823000 | . 2 -2.977478 | 10.324143 | -27.359398 | . 3 -11.822753 | 18.554853 | -19.376867 | . 4 20.115074 | -6.606486 | 3.406734 | . ... ... | ... | ... | . 20016 -27.179605 | 3.935340 | -3.374598 | . 20017 -8.964614 | -26.619114 | -1.062038 | . 20018 4.401250 | 22.954807 | 5.959539 | . 20019 1.569285 | 25.669464 | 4.684256 | . 20020 -14.252793 | 14.776907 | -20.378839 | . 20021 rows × 3 columns . df_res.columns = [&#39;x&#39;, &#39;y&#39;, &#39;z&#39;] . &#30452;&#25509;&#26174;&#31034; . test_df = cf.datagen.scatter3d(2,150,mode=&#39;stocks&#39;) . test_df.iplot(kind=&#39;scatter3d&#39;,x=&#39;x&#39;,y=&#39;y&#39;,z=&#39;z&#39;,size=15,categories=&#39;categories&#39;,text=&#39;text&#39;, title=&#39;Cufflinks - Scatter 3D Chart&#39;,colors=[&#39;blue&#39;,&#39;pink&#39;],width=0.5,margin=(0,0,0,0), opacity=1) . &#21152;&#19978;asFigure&#21442;&#25968; . # df_res.iplot(kind=&#39;scatter3d&#39;, x=&#39;x&#39;, y=&#39;y&#39;, z=&#39;z&#39;, size=5, color=&#39;red&#39;, layout=dict(height=500, width=700, margin=dict(b=0, t=0)), opacity=.8) . test_df.iplot(kind=&#39;scatter3d&#39;,x=&#39;x&#39;,y=&#39;y&#39;,z=&#39;z&#39;,size=15,categories=&#39;categories&#39;,text=&#39;text&#39;, title=&#39;Cufflinks - Scatter 3D Chart&#39;,colors=[&#39;blue&#39;,&#39;pink&#39;],width=0.5,margin=(0,0,0,0), opacity=1, asFigure=True) . &#30452;&#25509;&#26174;&#31034; . fig = test_df.iplot(kind=&#39;scatter3d&#39;,x=&#39;x&#39;,y=&#39;y&#39;,z=&#39;z&#39;,size=15,categories=&#39;categories&#39;,text=&#39;text&#39;, title=&#39;Cufflinks - Scatter 3D Chart&#39;,colors=[&#39;blue&#39;,&#39;pink&#39;],width=0.5,margin=(0,0,0,0), opacity=1, asFigure=True) . fig.show() . from IPython.display import HTML . HTML(fig.to_html()) . . . from matplotlib import cm import ipyvolume as ipv colormap = cm.Spectral # _c = [i*3 for i in pd.Categorical(df_res[&#39;id&#39;]).codes] # color = colormap(_c) ipv.quickscatter(df_res[0], df_res[1], df_res[2], size=1) # , marker=&quot;sphere&quot;, color=color[:,:3] . . . 从降维后的结果可以看到：这种方法提取的特征无法区分数据。 . &#22522;&#20110;ID&#20043;&#38388;&#20132;&#26131;&#30340;&#29305;&#24449;&#25552;&#21462; . 在数据从交易信息来看，没有明显的分布差别，所以在这里不予考虑。 . &#22522;&#20110;ID&#30340;&#29305;&#24449;&#25552;&#21462; . 从四个维度来提取： . 发起交易的金额总量和交易数； | 接收交易的金额总量和交易数； | . &#21457;&#36215;&#20132;&#26131;&#30340;&#37329;&#39069;&#24635;&#37327;&#21644;&#20132;&#26131;&#25968; . f = {&#39;cash_amount&#39;: [&#39;count&#39;, &#39;sum&#39;]} starter_df = df.groupby(&#39;starter_id&#39;).aggregate(f) starter_df.columns = [&#39;_&#39;.join(col).strip() for col in starter_df.columns.values] . starter_df.columns = [&#39;s_cash_amount_count&#39;, &#39;s_cash_amount_sum&#39;] . starter_df . s_cash_amount_count s_cash_amount_sum . starter_id . 1 1 | 2764000 | . 2 5 | 18098000 | . 3 3 | 8589800 | . 4 6 | 16682400 | . 5 2 | 5435500 | . ... ... | ... | . 6996 5 | 9014400 | . 6997 3 | 3548100 | . 6998 1 | 2878000 | . 6999 5 | 15088000 | . 7000 3 | 9085800 | . 6583 rows × 2 columns . &#25509;&#25910;&#20132;&#26131;&#30340;&#37329;&#39069;&#24635;&#37327;&#21644;&#20132;&#26131;&#25968; . f = {&#39;cash_amount&#39;: [&#39;count&#39;, &#39;sum&#39;]} receiver_df = df.groupby(&#39;receiver_id&#39;).aggregate(f) receiver_df.columns = [&#39;_&#39;.join(col).strip() for col in receiver_df.columns.values] . receiver_df.columns = [&#39;e_cash_amount_count&#39;, &#39;e_cash_amount_sum&#39;] receiver_df . e_cash_amount_count e_cash_amount_sum . receiver_id . 1 202 | 497892400 | . 2 179 | 457216300 | . 3 201 | 505419500 | . 4 214 | 539274100 | . 5 222 | 562892800 | . ... ... | ... | . 1434 1 | 8888800 | . 3012 1 | 405300 | . 4962 1 | 3279200 | . 5916 1 | 4554200 | . 6258 1 | 2977500 | . 117 rows × 2 columns . features = receiver_df.join(starter_df, how=&#39;outer&#39;) . # 填充NaN features = features.fillna(0) features . e_cash_amount_count e_cash_amount_sum s_cash_amount_count s_cash_amount_sum . 1 202.0 | 497892400.0 | 1.0 | 2764000.0 | . 2 179.0 | 457216300.0 | 5.0 | 18098000.0 | . 3 201.0 | 505419500.0 | 3.0 | 8589800.0 | . 4 214.0 | 539274100.0 | 6.0 | 16682400.0 | . 5 222.0 | 562892800.0 | 2.0 | 5435500.0 | . ... ... | ... | ... | ... | . 6996 0.0 | 0.0 | 5.0 | 9014400.0 | . 6997 0.0 | 0.0 | 3.0 | 3548100.0 | . 6998 0.0 | 0.0 | 1.0 | 2878000.0 | . 6999 0.0 | 0.0 | 5.0 | 15088000.0 | . 7000 0.0 | 0.0 | 3.0 | 9085800.0 | . 6596 rows × 4 columns . &#24402;&#19968;&#21270; . z_score_scaler = preprocessing.StandardScaler() z_score_feature = z_score_scaler.fit_transform(features) . _features = pd.DataFrame(z_score_feature, index=features.index) . _features . 0 1 2 3 . 1 8.122062 | 7.981598 | -1.276431 | -0.988593 | . 2 7.183164 | 7.319397 | 1.232125 | 2.134452 | . 3 8.081240 | 8.104138 | -0.022153 | 0.197936 | . 4 8.611921 | 8.655286 | 1.859264 | 1.846140 | . 5 8.938494 | 9.039796 | -0.649292 | -0.444493 | . ... ... | ... | ... | ... | . 6996 -0.123907 | -0.124019 | 1.232125 | 0.284414 | . 6997 -0.123907 | -0.124019 | -0.022153 | -0.828896 | . 6998 -0.123907 | -0.124019 | -1.276431 | -0.965374 | . 6999 -0.123907 | -0.124019 | 1.232125 | 1.521412 | . 7000 -0.123907 | -0.124019 | -0.022153 | 0.298956 | . 6596 rows × 4 columns . &#38477;&#32500;&#35266;&#23519;&#29305;&#24449;&#26377;&#25928;&#24615; . %%time from sklearn.manifold import TSNE tsne = TSNE(n_components=3) _res = tsne.fit_transform(_features) . CPU times: user 3min 30s, sys: 128 ms, total: 3min 30s Wall time: 25.5 s . df_res = pd.DataFrame(index=_features.index) for i in range(3): df_res[i] = _res[:, i] . df_res.reset_index(inplace=True) . df_res . index 0 1 2 . 0 0 | -2.616519 | 10.399817 | 16.650976 | . 1 1 | 0.269044 | 8.815780 | 21.424440 | . 2 2 | -1.138858 | 9.294405 | 19.571409 | . 3 3 | -0.300031 | 9.371153 | 21.505943 | . 4 4 | -3.027676 | 11.100630 | 18.954000 | . ... ... | ... | ... | ... | . 6591 6591 | 9.084714 | 10.959700 | -5.038331 | . 6592 6592 | -4.531178 | 27.202545 | -1.383322 | . 6593 6593 | -14.335349 | -15.130382 | -5.814716 | . 6594 6594 | 1.527327 | -24.622822 | -3.664261 | . 6595 6595 | -22.862921 | -3.276567 | 5.567962 | . 6596 rows × 4 columns . from matplotlib import cm import ipyvolume as ipv colormap = cm.Spectral # _c = [i*3 for i in pd.Categorical(df_res[&#39;id&#39;]).codes] # color = colormap(_c) ipv.quickscatter(df_res[0], df_res[1], df_res[2], size=1) # , marker=&quot;sphere&quot;, color=color[:,:3] . . . 从降维后的结果可以看到：这种方法提取的特征很容易异常数据。 . &#26500;&#24314;&#27169;&#22411; . 使用下面3种方式构建模型： . K-means； | 谱聚类模型； | 孤立森林Isolation Forest。 | . K-means&#32858;&#31867;&#27169;&#22411; . %%time from sklearn.cluster import KMeans y_pred = KMeans(n_clusters=2, random_state=10).fit_predict(_features) . CPU times: user 143 ms, sys: 299 ms, total: 442 ms Wall time: 39.2 ms . from matplotlib import cm import ipyvolume as ipv df_res = _features.reset_index() # pd.Categorical(y_pred).codes colormap = cm.Spectral _c = [i*100 for i in pd.Categorical(y_pred).codes] color = colormap(_c) ipv.quickscatter(df_res[0], df_res[1], df_res[3], size=2, marker=&quot;sphere&quot;, color=color[:,:3]) . . _df = pd.DataFrame(y_pred, index=_features.index) . features.loc[_df[_df[0]==1].index] . e_cash_amount_count e_cash_amount_sum s_cash_amount_count s_cash_amount_sum . 1 202.0 | 497892400.0 | 1.0 | 2764000.0 | . 2 179.0 | 457216300.0 | 5.0 | 18098000.0 | . 3 201.0 | 505419500.0 | 3.0 | 8589800.0 | . 4 214.0 | 539274100.0 | 6.0 | 16682400.0 | . 5 222.0 | 562892800.0 | 2.0 | 5435500.0 | . ... ... | ... | ... | ... | . 96 208.0 | 508578500.0 | 0.0 | 0.0 | . 97 191.0 | 443328700.0 | 1.0 | 4635800.0 | . 98 187.0 | 468610000.0 | 2.0 | 5157900.0 | . 99 182.0 | 431347100.0 | 3.0 | 10525300.0 | . 100 217.0 | 580785900.0 | 2.0 | 3329900.0 | . 100 rows × 4 columns . . 耗时39ms，但效果很差。 . &#35889;&#32858;&#31867;&#27169;&#22411; . %%time from sklearn.cluster import SpectralClustering y_pred = SpectralClustering(n_clusters=2).fit_predict(_features) . CPU times: user 19.1 s, sys: 18 s, total: 37.1 s Wall time: 6.64 s . from matplotlib import cm import ipyvolume as ipv df_res = _features.reset_index() # pd.Categorical(y_pred).codes colormap = cm.Spectral _c = [i*100 for i in pd.Categorical(y_pred).codes] color = colormap(_c) ipv.quickscatter(df_res[0], df_res[1], df_res[3], size=2, marker=&quot;sphere&quot;, color=color[:,:3]) . _df = pd.DataFrame(y_pred, index=_features.index) . _df[_df[0]==1] . 0 . 1137 1 | . features.loc[_df[_df[0]==1].index] . e_cash_amount_count e_cash_amount_sum s_cash_amount_count s_cash_amount_sum . 1137 0.0 | 0.0 | 12.0 | 106665600.0 | . . . 耗时6.46s，效果很好。 . . 异常数据为： . . IsolationForest&#26041;&#27861; . features = _features . %%time import numpy as np import matplotlib.pyplot as plt from sklearn.ensemble import IsolationForest from scipy import stats rng = np.random.RandomState(42) # 构造训练样本 n_samples = features.shape[0] #样本总数 outliers_fraction = 1/n_samples #异常样本比例 clf = IsolationForest(max_samples=n_samples , random_state=rng, contamination=outliers_fraction) # , random_state=rng, contamination=outliers_fraction clf.fit(features) # y_pred_train = clf.predict(X_train) scores_pred = clf.decision_function(features) threshold = stats.scoreatpercentile(scores_pred, 100 * outliers_fraction) #根据训练样本中异常样本比例，得到阈值，用于绘图 . CPU times: user 616 ms, sys: 995 µs, total: 617 ms Wall time: 616 ms . scores_pred . array([0.19802162, 0.08466044, 0.21168621, ..., 0.38757413, 0.38741914, 0.42611375]) . threshold . 5.525365321529252e-17 . _df = pd.DataFrame(scores_pred) . res = _df[_df[0] &lt; threshold] . features.iloc[res.index] . e_cash_amount_count e_cash_amount_sum s_cash_amount_count s_cash_amount_sum . 1137 0.0 | 0.0 | 12.0 | 106665600.0 | . . 效果：耗时616ms，结果准确。 . &#27169;&#22411;&#27604;&#36739; . 从运行结果来看，三种模型里： . K-Means效果最差，其余两种效果很好； | 谱聚类模型性能比较差，运行时间是Isolation Forest模型的6倍。 | . TODO . 降到二维/三维可视化展示聚类效果。 | .",
            "url": "https://donyum.github.io/blog/jupyter/2020/04/18/Ali-Ant_v2_1.html",
            "relUrl": "/jupyter/2020/04/18/Ali-Ant_v2_1.html",
            "date": " • Apr 18, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "docker添加GPU支持",
            "content": "起因 . 安装pytorch的时候发现NVIDIA驱动版本太低，各种不兼容，于是从390（CUDA 8.0）升级到了430（CUDA 10.1），重启后docker挂了，于是重装、各种配置。 . 虽然过程多少有些曲折，但结果是好的——以后再也不用在GPU相关软件上抓耳挠腮了。 . 关于软件版本的选择，已经在MongoDB、werkzeug、mongoengine、pymongo、faiss、pytorch上吃过很多亏了，经验就是： . 驱动、软件版本还是尽可能使用最新稳定版！出问题后才考虑二分法回退测试。 . 遇到的坑 . nvidia-docker安装 . nvidia-docker安装方法 . nvidia-docker WIKI . docker-compose的支持 . –gpus选项不支持 . docker最新版本0.19使用--gpus [all/N]选项可以原生支持GPU资源：docker run --gpus all nvidia/cuda:10.0-base nvidia-smi . 但是docker-compose不支持该选项. . 所以这条路走不通。 . 使用runtime方式 . 测试runtime的方法：docker run --runtime=nvidia nvidia/cuda:10.0-base nvidia-smi . | 添加nvidia runtime： . /etc/docker/daemon.json . { &quot;runtimes&quot;: { &quot;nvidia&quot;: { &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;, &quot;runtimeArgs&quot;: [] } } } . 然后重启服务。 . | docker-compose.yml . 需要注意两点：只有2.3版本支持runtime选项，设置runtime: nvidia。Demo： . $ cat docker-compose.yml version: &#39;2.3&#39; services: nvidia-smi-test: runtime: nvidia image: nvidia/cuda:9.2-runtime-centos7 . | . 参考： . Support for NVIDIA GPUs under Docker Compose | nvidia-container-runtime | .",
            "url": "https://donyum.github.io/blog/markdown/2020/04/17/docker-with-GPU-support.html",
            "relUrl": "/markdown/2020/04/17/docker-with-GPU-support.html",
            "date": " • Apr 17, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://donyum.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "rem大环路时延分析",
            "content": "import pandas as pd import numpy as np . rem_reqOrderInsert = pd.read_csv(&#39;./RemReqOrderInsert-2020_04_22.csv&#39;) . rem_reqOrderInsert_a = pd.read_csv(&#39;./RemReqOrderInsert-2020_04_22_a.csv&#39;) . rem_reqOrderInsert.head() . MMSec MMNSec SrcIP SrcPort DestIP DestPort UserID Symbol AccountID OrderType ... SessionSelMode OrderToken SecType Value1 Value2 Value3 TIF Exchange MinQuantity CusField . 0 1710051 | 825096324 | 10.8.4.114 | 55414 | 10.8.4.55 | 20000 | 20 | i2009 | 85011009 | 1 | ... | 1 | 128 | 3 | 9 | 16 | 13 | 99998 | 104 | 0 | 0 | . 1 1710051 | 825107604 | 10.8.4.114 | 55438 | 10.8.4.55 | 20000 | 12 | i2009 | 85011210 | 1 | ... | 1 | 1184 | 3 | 9 | 16 | 13 | 99998 | 104 | 0 | 0 | . 2 1710051 | 825109012 | 10.8.4.114 | 55434 | 10.8.4.55 | 20000 | 13 | i2009 | 80700501 | 1 | ... | 1 | 978 | 3 | 9 | 16 | 13 | 99998 | 104 | 0 | 0 | . 3 1710052 | 310685560 | 10.8.4.114 | 55434 | 10.8.4.55 | 20000 | 13 | i2009 | 80700501 | 1 | ... | 1 | 979 | 3 | 9 | 16 | 13 | 99998 | 104 | 0 | 0 | . 4 1710054 | 286102615 | 10.8.4.114 | 55428 | 10.8.4.55 | 20000 | 16 | i2009 | 85010987 | 1 | ... | 1 | 728 | 3 | 9 | 16 | 13 | 99998 | 104 | 0 | 0 | . 5 rows × 25 columns . len(rem_reqOrderInsert) . 341 . rem_OrderAccept = pd.read_csv(&#39;./RemOrderAccept-2020_04_22.csv&#39;) . rem_OrderAccept_a = pd.read_csv(&#39;./RemOrderAccept-2020_04_22_a.csv&#39;) . rem_MarketAccept = pd.read_csv(&#39;./RemMarketAccept-2020_04_22.csv&#39;) . rem_MarketAccept_a = pd.read_csv(&#39;./RemMarketAccept-2020_04_22_a.csv&#39;) . rem_OrderAccept.head() . MMSec MMNSec SrcIP SrcPort DestIP DestPort UserID MsgType Timestamp OrderToken ... Symbol Price TIF AccountID HedgeFlag Exchange MinQuantity CusField OrderRef OrderStatus . 0 1710051 | 825098723 | 10.8.4.55 | 20000 | 10.8.4.114 | 55414 | 20 | 10 | 0 | 128 | ... | i2009 | 602.5 | 99998 | 85011009 | 2 | 104 | 0 | 0 | 134353416 | 1 | . 1 1710051 | 825110003 | 10.8.4.55 | 20000 | 10.8.4.114 | 55438 | 12 | 10 | 0 | 1184 | ... | i2009 | 602.5 | 99998 | 85011210 | 2 | 104 | 0 | 0 | 135401472 | 1 | . 2 1710051 | 825111411 | 10.8.4.55 | 20000 | 10.8.4.114 | 55434 | 13 | 10 | 0 | 978 | ... | i2009 | 603.0 | 99998 | 80700501 | 2 | 104 | 0 | 0 | 135401984 | 1 | . 3 1710052 | 310687959 | 10.8.4.55 | 20000 | 10.8.4.114 | 55434 | 13 | 10 | 0 | 979 | ... | i2009 | 603.0 | 99998 | 80700501 | 2 | 104 | 0 | 0 | 135401480 | 1 | . 4 1710054 | 286104984 | 10.8.4.55 | 20000 | 10.8.4.114 | 55428 | 16 | 10 | 0 | 728 | ... | i2009 | 603.0 | 99998 | 85010987 | 2 | 104 | 0 | 0 | 135401992 | 1 | . 5 rows × 24 columns . len(rem_OrderAccept) . 341 . rem_MarketAccept.head() . MMSec MMNSec SrcIP SrcPort DestIP DestPort Timestamp OrderRef OrderSysID AccountID UserID OrderToken . 0 1710051 | 826387703 | 10.8.4.55 | 20000 | 10.8.4.114 | 55414 | 286330453312 | 134353416 | 35581185 | 85011009 | 20 | 128 | . 1 1710051 | 826609462 | 10.8.4.55 | 20000 | 10.8.4.114 | 55438 | 286330453312 | 135401472 | 35581186 | 85011210 | 12 | 1184 | . 2 1710051 | 826614171 | 10.8.4.55 | 20000 | 10.8.4.114 | 55434 | 286330453312 | 135401984 | 35581187 | 80700501 | 13 | 978 | . 3 1710052 | 311834529 | 10.8.4.55 | 20000 | 10.8.4.114 | 55434 | 286327056000 | 135401480 | 35581516 | 80700501 | 13 | 979 | . 4 1710054 | 287286534 | 10.8.4.55 | 20000 | 10.8.4.114 | 55428 | 286335387776 | 135401992 | 35582377 | 85010987 | 16 | 728 | . len(rem_MarketAccept) . 341 . len(rem_reqOrderInsert[&#39;OrderToken&#39;].unique()) . 341 . rem_Order_merge = rem_reqOrderInsert.merge(rem_OrderAccept,on=[&#39;OrderToken&#39;]) . rem_Order_merge_a = rem_reqOrderInsert_a.merge(rem_OrderAccept_a,on=[&#39;OrderToken&#39;]) . rem_Order_merge.head() . MMSec_x MMNSec_x SrcIP_x SrcPort_x DestIP_x DestPort_x UserID_x Symbol_x AccountID_x OrderType_x ... Symbol_y Price_y TIF_y AccountID_y HedgeFlag_y Exchange_y MinQuantity_y CusField_y OrderRef OrderStatus . 0 1710051 | 825096324 | 10.8.4.114 | 55414 | 10.8.4.55 | 20000 | 20 | i2009 | 85011009 | 1 | ... | i2009 | 602.5 | 99998 | 85011009 | 2 | 104 | 0 | 0 | 134353416 | 1 | . 1 1710051 | 825107604 | 10.8.4.114 | 55438 | 10.8.4.55 | 20000 | 12 | i2009 | 85011210 | 1 | ... | i2009 | 602.5 | 99998 | 85011210 | 2 | 104 | 0 | 0 | 135401472 | 1 | . 2 1710051 | 825109012 | 10.8.4.114 | 55434 | 10.8.4.55 | 20000 | 13 | i2009 | 80700501 | 1 | ... | i2009 | 603.0 | 99998 | 80700501 | 2 | 104 | 0 | 0 | 135401984 | 1 | . 3 1710052 | 310685560 | 10.8.4.114 | 55434 | 10.8.4.55 | 20000 | 13 | i2009 | 80700501 | 1 | ... | i2009 | 603.0 | 99998 | 80700501 | 2 | 104 | 0 | 0 | 135401480 | 1 | . 4 1710054 | 286102615 | 10.8.4.114 | 55428 | 10.8.4.55 | 20000 | 16 | i2009 | 85010987 | 1 | ... | i2009 | 603.0 | 99998 | 85010987 | 2 | 104 | 0 | 0 | 135401992 | 1 | . 5 rows × 48 columns . rem_Order_merge[&#39;delta&#39;] = (rem_Order_merge[&#39;MMSec_y&#39;]*10e8+rem_Order_merge[&#39;MMNSec_y&#39;]) - (rem_Order_merge[&#39;MMSec_x&#39;]*10e8+rem_Order_merge[&#39;MMNSec_x&#39;]) . rem_Order_merge_a[&#39;delta&#39;] = (rem_Order_merge_a[&#39;MMSec_y&#39;]*10e8+rem_Order_merge_a[&#39;MMNSec_y&#39;]) - (rem_Order_merge_a[&#39;MMSec_x&#39;]*10e8+rem_Order_merge_a[&#39;MMNSec_x&#39;]) . rem_Order_merge.delta.describe() . count 341.000000 mean 2406.255132 std 290.958724 min 1795.000000 25% 2399.000000 50% 2399.000000 75% 2400.000000 max 3509.000000 Name: delta, dtype: float64 . rem_Order_merge_a.delta.describe() . count 1.027300e+04 mean 2.410289e+03 std 5.259184e+11 min -4.376214e+12 25% 2.399000e+03 50% 2.518000e+03 75% 2.519000e+03 max 4.376214e+12 Name: delta, dtype: float64 . rem_MarketOrder_merge = rem_reqOrderInsert.merge(rem_MarketAccept,on=[&#39;OrderToken&#39;]) . rem_MarketOrder_merge_a = rem_reqOrderInsert_a.merge(rem_MarketAccept_a,on=[&#39;OrderToken&#39;]) . rem_MarketOrder_merge.head() . MMSec_x MMNSec_x SrcIP_x SrcPort_x DestIP_x DestPort_x UserID_x Symbol AccountID_x OrderType ... MMNSec_y SrcIP_y SrcPort_y DestIP_y DestPort_y Timestamp OrderRef OrderSysID AccountID_y UserID_y . 0 1710051 | 825096324 | 10.8.4.114 | 55414 | 10.8.4.55 | 20000 | 20 | i2009 | 85011009 | 1 | ... | 826387703 | 10.8.4.55 | 20000 | 10.8.4.114 | 55414 | 286330453312 | 134353416 | 35581185 | 85011009 | 20 | . 1 1710051 | 825107604 | 10.8.4.114 | 55438 | 10.8.4.55 | 20000 | 12 | i2009 | 85011210 | 1 | ... | 826609462 | 10.8.4.55 | 20000 | 10.8.4.114 | 55438 | 286330453312 | 135401472 | 35581186 | 85011210 | 12 | . 2 1710051 | 825109012 | 10.8.4.114 | 55434 | 10.8.4.55 | 20000 | 13 | i2009 | 80700501 | 1 | ... | 826614171 | 10.8.4.55 | 20000 | 10.8.4.114 | 55434 | 286330453312 | 135401984 | 35581187 | 80700501 | 13 | . 3 1710052 | 310685560 | 10.8.4.114 | 55434 | 10.8.4.55 | 20000 | 13 | i2009 | 80700501 | 1 | ... | 311834529 | 10.8.4.55 | 20000 | 10.8.4.114 | 55434 | 286327056000 | 135401480 | 35581516 | 80700501 | 13 | . 4 1710054 | 286102615 | 10.8.4.114 | 55428 | 10.8.4.55 | 20000 | 16 | i2009 | 85010987 | 1 | ... | 287286534 | 10.8.4.55 | 20000 | 10.8.4.114 | 55428 | 286335387776 | 135401992 | 35582377 | 85010987 | 16 | . 5 rows × 36 columns . rem_MarketOrder_merge[&#39;delta&#39;] = (rem_MarketOrder_merge[&#39;MMSec_y&#39;]*10e8+rem_MarketOrder_merge[&#39;MMNSec_y&#39;]) - (rem_MarketOrder_merge[&#39;MMSec_x&#39;]*10e8+rem_MarketOrder_merge[&#39;MMNSec_x&#39;]) . rem_MarketOrder_merge_a[&#39;delta&#39;] = (rem_MarketOrder_merge_a[&#39;MMSec_y&#39;]*10e8+rem_MarketOrder_merge_a[&#39;MMNSec_y&#39;]) - (rem_MarketOrder_merge_a[&#39;MMSec_x&#39;]*10e8+rem_MarketOrder_merge_a[&#39;MMNSec_x&#39;]) . rem_MarketOrder_merge.delta.describe() . count 3.410000e+02 mean 2.917711e+06 std 1.770356e+06 min 1.030408e+06 25% 1.689747e+06 50% 2.560682e+06 75% 3.595494e+06 max 9.533607e+06 Name: delta, dtype: float64 . rem_MarketOrder_merge_a = rem_MarketOrder_merge_a.loc[(rem_MarketOrder_merge_a[&#39;delta&#39;]&lt;10e8) &amp; (rem_MarketOrder_merge_a[&#39;delta&#39;]&gt;0)] . rem_MarketOrder_merge_a.delta.describe() . count 9.899000e+03 mean 3.334236e+06 std 2.390998e+06 min 9.409780e+05 25% 1.785286e+06 50% 2.653197e+06 75% 4.069515e+06 max 8.664288e+07 Name: delta, dtype: float64 . delta_market_order = rem_MarketOrder_merge.delta.tolist() sections = [0,1000000,2000000,3000000,4000000,5000000,6000000,7000000,8000000,9000000,10000000,20000000] group_names = [&#39;0-1ms&#39;,&#39;1-2ms&#39;,&#39;2-3ms&#39;,&#39;3-4ms&#39;,&#39;4-5ms&#39;,&#39;5-6ms&#39;,&#39;6-7ms&#39;,&#39;7-8ms&#39;,&#39;8-9ms&#39;,&#39;9-10ms&#39;,&#39;10-20ms&#39;] cuts1 = pd.cut(delta_market_order,sections,labels=group_names) . cuts1.value_counts().plot(kind=&#39;bar&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f32fe3925c0&gt; . delta_market_order_a = rem_MarketOrder_merge_a.delta.tolist() sections = [0,1000000,2000000,3000000,4000000,5000000,6000000,7000000,8000000,9000000,10000000,20000000,100000000] group_names = [&#39;0-1ms&#39;,&#39;1-2ms&#39;,&#39;2-3ms&#39;,&#39;3-4ms&#39;,&#39;4-5ms&#39;,&#39;5-6ms&#39;,&#39;6-7ms&#39;,&#39;7-8ms&#39;,&#39;8-9ms&#39;,&#39;9-10ms&#39;,&#39;10-20ms&#39;,&#39;20-100ms&#39;] cuts = pd.cut(delta_market_order_a,sections,labels=group_names) . cuts.value_counts().plot(kind=&#39;bar&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f32fde31278&gt; . type(cuts1.value_counts()) . pandas.core.series.Series . cuts1.value_counts()/cuts1.value_counts().sum() . 0-1ms 0.000000 1-2ms 0.366569 2-3ms 0.243402 3-4ms 0.237537 4-5ms 0.055718 5-6ms 0.029326 6-7ms 0.017595 7-8ms 0.014663 8-9ms 0.020528 9-10ms 0.014663 10-20ms 0.000000 dtype: float64 . import matplotlib.pyplot as plt labels = cuts1.value_counts().index.tolist() sizes = cuts1.value_counts().tolist() explode = (0, 0, 0, 0,0,0,0,0,0,0,0) # only &quot;explode&quot; the 2nd slice (i.e. &#39;Hogs&#39;) fig1, ax1 = plt.subplots() ax1.pie(sizes, explode=explode, labels=labels, autopct=&#39;%1.1f%%&#39;, shadow=True, startangle=90) ax1.axis(&#39;equal&#39;) # Equal aspect ratio ensures that pie is drawn as a circle. plt.show() . import matplotlib.pyplot as plt labels = cuts.value_counts().index.tolist() sizes = cuts.value_counts().tolist() explode = (0, 0, 0, 0,0,0,0,0,0,0,0,0) # only &quot;explode&quot; the 2nd slice (i.e. &#39;Hogs&#39;) fig1, ax1 = plt.subplots() ax1.pie(sizes, explode=explode, labels=labels, autopct=&#39;%1.1f%%&#39;, shadow=True, startangle=90) ax1.axis(&#39;equal&#39;) # Equal aspect ratio ensures that pie is drawn as a circle. plt.show() . cuts.value_counts().index . CategoricalIndex([&#39;0-1ms&#39;, &#39;1-2ms&#39;, &#39;2-3ms&#39;, &#39;3-4ms&#39;, &#39;4-5ms&#39;, &#39;5-6ms&#39;, &#39;6-7ms&#39;, &#39;7-8ms&#39;, &#39;8-9ms&#39;, &#39;9-10ms&#39;, &#39;10-20ms&#39;, &#39;20-100ms&#39;], categories=[&#39;0-1ms&#39;, &#39;1-2ms&#39;, &#39;2-3ms&#39;, &#39;3-4ms&#39;, &#39;4-5ms&#39;, &#39;5-6ms&#39;, &#39;6-7ms&#39;, &#39;7-8ms&#39;, ...], ordered=True, dtype=&#39;category&#39;) . rem_MarketOrder_merge.columns . Index([&#39;MMSec_x&#39;, &#39;MMNSec_x&#39;, &#39;SrcIP_x&#39;, &#39;SrcPort_x&#39;, &#39;DestIP_x&#39;, &#39;DestPort_x&#39;, &#39;UserID_x&#39;, &#39;Symbol&#39;, &#39;AccountID_x&#39;, &#39;OrderType&#39;, &#39;Side&#39;, &#39;Quantity&#39;, &#39;Price&#39;, &#39;HedgeFlag&#39;, &#39;SessionID&#39;, &#39;SessionSelMode&#39;, &#39;OrderToken&#39;, &#39;SecType&#39;, &#39;Value1&#39;, &#39;Value2&#39;, &#39;Value3&#39;, &#39;TIF&#39;, &#39;Exchange&#39;, &#39;MinQuantity&#39;, &#39;CusField&#39;, &#39;MMSec_y&#39;, &#39;MMNSec_y&#39;, &#39;SrcIP_y&#39;, &#39;SrcPort_y&#39;, &#39;DestIP_y&#39;, &#39;DestPort_y&#39;, &#39;Timestamp&#39;, &#39;OrderRef&#39;, &#39;OrderSysID&#39;, &#39;AccountID_y&#39;, &#39;UserID_y&#39;, &#39;delta&#39;, &#39;rate&#39;], dtype=&#39;object&#39;) . rem_MarketOrder_merge_group = rem_MarketOrder_merge.groupby(&#39;SessionID&#39;) . rem_MarketOrder_merge_group.size() . SessionID 0 7 4 64 5 44 6 54 7 29 8 117 9 26 dtype: int64 . rem_MarketOrder_merge_group_a = rem_MarketOrder_merge_a.groupby(&#39;SessionID&#39;) . rem_MarketOrder_merge_group_a.size() . SessionID 0 5115 4 1866 5 494 6 639 7 447 8 942 9 396 dtype: int64 . rem_MarketOrder_merge_group_a.get_group(0).delta.describe() . count 5.115000e+03 mean 3.441799e+06 std 2.627466e+06 min 9.409780e+05 25% 1.781162e+06 50% 2.674885e+06 75% 4.236013e+06 max 8.664288e+07 Name: delta, dtype: float64 . delta_market_order = rem_MarketOrder_merge_group_a.get_group(0).delta.tolist() sections = [0,1000000,2000000,3000000,4000000,5000000,6000000,7000000,8000000,9000000,10000000,20000000] group_names = [&#39;0-1ms&#39;,&#39;1-2ms&#39;,&#39;2-3ms&#39;,&#39;3-4ms&#39;,&#39;4-5ms&#39;,&#39;5-6ms&#39;,&#39;6-7ms&#39;,&#39;7-8ms&#39;,&#39;8-9ms&#39;,&#39;9-10ms&#39;,&#39;10-20ms&#39;] cuts1 = pd.cut(delta_market_order,sections,labels=group_names) cuts1.value_counts().plot(kind=&#39;bar&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f32fdbd8f60&gt; . delta_market_order = rem_MarketOrder_merge_group_a.get_group(4).delta.tolist() sections = [0,1000000,2000000,3000000,4000000,5000000,6000000,7000000,8000000,9000000,10000000,20000000] group_names = [&#39;0-1ms&#39;,&#39;1-2ms&#39;,&#39;2-3ms&#39;,&#39;3-4ms&#39;,&#39;4-5ms&#39;,&#39;5-6ms&#39;,&#39;6-7ms&#39;,&#39;7-8ms&#39;,&#39;8-9ms&#39;,&#39;9-10ms&#39;,&#39;10-20ms&#39;] cuts1 = pd.cut(delta_market_order,sections,labels=group_names) cuts1.value_counts().plot(kind=&#39;bar&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f32fdc04240&gt; . delta_market_order = rem_MarketOrder_merge_group_a.get_group(5).delta.tolist() sections = [0,1000000,2000000,3000000,4000000,5000000,6000000,7000000,8000000,9000000,10000000,20000000] group_names = [&#39;0-1ms&#39;,&#39;1-2ms&#39;,&#39;2-3ms&#39;,&#39;3-4ms&#39;,&#39;4-5ms&#39;,&#39;5-6ms&#39;,&#39;6-7ms&#39;,&#39;7-8ms&#39;,&#39;8-9ms&#39;,&#39;9-10ms&#39;,&#39;10-20ms&#39;] cuts1 = pd.cut(delta_market_order,sections,labels=group_names) cuts1.value_counts().plot(kind=&#39;bar&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f32fdb2a470&gt; . delta_market_order = rem_MarketOrder_merge_group_a.get_group(6).delta.tolist() sections = [0,1000000,2000000,3000000,4000000,5000000,6000000,7000000,8000000,9000000,10000000,20000000] group_names = [&#39;0-1ms&#39;,&#39;1-2ms&#39;,&#39;2-3ms&#39;,&#39;3-4ms&#39;,&#39;4-5ms&#39;,&#39;5-6ms&#39;,&#39;6-7ms&#39;,&#39;7-8ms&#39;,&#39;8-9ms&#39;,&#39;9-10ms&#39;,&#39;10-20ms&#39;] cuts1 = pd.cut(delta_market_order,sections,labels=group_names) cuts1.value_counts().plot(kind=&#39;bar&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f32fda720b8&gt; . delta_market_order = rem_MarketOrder_merge_group_a.get_group(7).delta.tolist() sections = [0,1000000,2000000,3000000,4000000,5000000,6000000,7000000,8000000,9000000,10000000,20000000] group_names = [&#39;0-1ms&#39;,&#39;1-2ms&#39;,&#39;2-3ms&#39;,&#39;3-4ms&#39;,&#39;4-5ms&#39;,&#39;5-6ms&#39;,&#39;6-7ms&#39;,&#39;7-8ms&#39;,&#39;8-9ms&#39;,&#39;9-10ms&#39;,&#39;10-20ms&#39;] cuts1 = pd.cut(delta_market_order,sections,labels=group_names) cuts1.value_counts().plot(kind=&#39;bar&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f32fd9f7780&gt; . delta_market_order = rem_MarketOrder_merge_group_a.get_group(8).delta.tolist() sections = [0,1000000,2000000,3000000,4000000,5000000,6000000,7000000,8000000,9000000,10000000,20000000] group_names = [&#39;0-1ms&#39;,&#39;1-2ms&#39;,&#39;2-3ms&#39;,&#39;3-4ms&#39;,&#39;4-5ms&#39;,&#39;5-6ms&#39;,&#39;6-7ms&#39;,&#39;7-8ms&#39;,&#39;8-9ms&#39;,&#39;9-10ms&#39;,&#39;10-20ms&#39;] cuts1 = pd.cut(delta_market_order,sections,labels=group_names) cuts1.value_counts().plot(kind=&#39;bar&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f32fd9d8898&gt; . delta_market_order = rem_MarketOrder_merge_group_a.get_group(9).delta.tolist() sections = [0,1000000,2000000,3000000,4000000,5000000,6000000,7000000,8000000,9000000,10000000,20000000] group_names = [&#39;0-1ms&#39;,&#39;1-2ms&#39;,&#39;2-3ms&#39;,&#39;3-4ms&#39;,&#39;4-5ms&#39;,&#39;5-6ms&#39;,&#39;6-7ms&#39;,&#39;7-8ms&#39;,&#39;8-9ms&#39;,&#39;9-10ms&#39;,&#39;10-20ms&#39;] cuts1 = pd.cut(delta_market_order,sections,labels=group_names) cuts1.value_counts().plot(kind=&#39;bar&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f32fda63da0&gt; .",
            "url": "https://donyum.github.io/blog/%E6%97%B6%E5%BB%B6%E5%88%86%E6%9E%90/2020/01/18/rem-delay-analyze.html",
            "relUrl": "/%E6%97%B6%E5%BB%B6%E5%88%86%E6%9E%90/2020/01/18/rem-delay-analyze.html",
            "date": " • Jan 18, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://donyum.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ".",
          "url": "https://donyum.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://donyum.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}