{
  
    
        "post0": {
            "title": "异常点检测模型",
            "content": "import sys import time # import logging import datetime from pathlib import Path import numpy as np import pandas as pd from pandas.tseries.offsets import * # import plotly_express as px # import cufflinks as cf from sklearn import preprocessing from tqdm import tqdm_notebook as tqdm . &#25968;&#25454;&#21152;&#36733; . #collapse-hide df = pd.read_csv(&#39;./sample_21.txt&#39;) df . . 交易时间 交易金额 转账附言 渠道 发起方id 发起方年龄 发起方所处地区 接收方ID . 0 2017-12-23 00:07:36 | 1989200 | 转账 | 普通转账 | 3655 | 22 | 广东 | 44 | . 1 2017-12-23 00:08:25 | 4802500 | - | 线下付款 | 2703 | 50 | 新疆 | 47 | . 2 2017-12-23 00:12:37 | 3254000 | - | 线上付款 | 3476 | 36 | 安徽 | 92 | . 3 2017-12-23 00:12:50 | 3458600 | - | 线下付款 | 6017 | 31 | 贵州 | 43 | . 4 2017-12-23 00:13:21 | 2085400 | 奖金 | 普通转账 | 1904 | 37 | 云南 | 18 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 20016 2018-02-28 14:07:39 | 2515300 | 上次买的xx | 跨境转账 | 304 | 23 | 美国 | 71 | . 20017 2018-02-28 14:35:16 | 4910500 | 李xx给张xx的钱 | 普通转账 | 3689 | 32 | 黑龙江 | 55 | . 20018 2018-02-28 14:40:07 | 3096400 | 李xx给张xx的钱 | 普通转账 | 320 | 35 | 上海 | 24 | . 20019 2018-02-28 14:41:10 | 3661000 | 还给你 | 普通转账 | 3909 | 42 | 上海 | 90 | . 20020 2018-02-28 14:45:10 | 3049800 | 奖金 | 跨境转账 | 2525 | 31 | 美国 | 32 | . 20021 rows × 8 columns . df.columns = [&#39;time&#39;, &#39;cash_amount&#39;, &#39;comment&#39;, &#39;channel&#39;, &#39;starter_id&#39;, &#39;starter_age&#39;, &#39;starter_area&#39;, &#39;receiver_id&#39;] df.describe() . cash_amount starter_id starter_age receiver_id . count 2.002100e+04 | 20021.000000 | 20021.000000 | 20021.000000 | . mean 2.509762e+06 | 3498.215674 | 33.934369 | 51.956895 | . std 1.446299e+06 | 2013.401076 | 9.564053 | 80.228028 | . min 1.010000e+04 | 1.000000 | 18.000000 | 1.000000 | . 25% 1.264900e+06 | 1754.000000 | 26.000000 | 26.000000 | . 50% 2.492100e+06 | 3500.000000 | 34.000000 | 51.000000 | . 75% 3.751800e+06 | 5238.000000 | 42.000000 | 76.000000 | . max 8.888800e+06 | 7000.000000 | 88.000000 | 6258.000000 | . &#25968;&#25454;&#25506;&#32034; . . Note: 详见《AliAntTest_数据探索.pdf》。 . &#29305;&#24449;&#25552;&#21462; . 尝试从下面三个维度提取特征，并比较提取特征的优劣： . 基于事实表的特征提取 | 基于ID之间交易的特征提取 | 基于ID的特征提取 | PS：其实从数据探索过程中可以发现第3种最好，但实际场景下特征维度会非常多，所以特征提取前期应该尽可能多的探索一下。 . &#22522;&#20110;&#20107;&#23454;&#34920;&#30340;&#29305;&#24449;&#25552;&#21462; . 可用于构造特征的维度有： . 交易金额； | 交易数量； | 发起地区； | 年龄； | 渠道； | 时间； | . z-score&#26631;&#20934;&#21270;: &#20132;&#26131;&#37329;&#39069;&#12289;&#24180;&#40836; . z_score_scaler = preprocessing.StandardScaler() z_score_feature = z_score_scaler.fit_transform(df[[&#39;cash_amount&#39;, &#39;starter_age&#39;]]) . features = pd.DataFrame(z_score_feature, columns=[&#39;cash_amount&#39;, &#39;starter_age&#39;]) . features . cash_amount starter_age . 0 -0.359936 | -1.247867 | . 1 1.585284 | 1.679835 | . 2 0.514594 | 0.215984 | . 3 0.656062 | -0.306820 | . 4 -0.293420 | 0.320545 | . ... ... | ... | . 20016 0.003829 | -1.143306 | . 20017 1.659959 | -0.202259 | . 20018 0.405623 | 0.111423 | . 20019 0.796009 | 0.843349 | . 20020 0.373402 | -0.306820 | . 20021 rows × 2 columns . OneHot&#8212;&#8212;&#28192;&#36947; . ch_one_hot_enc = preprocessing.OneHotEncoder() ch_one_hot_enc.fit(df[[&#39;channel&#39;]]) # enc.n_values_ . OneHotEncoder(categories=&#39;auto&#39;, drop=None, dtype=&lt;class &#39;numpy.float64&#39;&gt;, handle_unknown=&#39;error&#39;, sparse=True) . ch_one_hot_enc . OneHotEncoder(categories=&#39;auto&#39;, drop=None, dtype=&lt;class &#39;numpy.float64&#39;&gt;, handle_unknown=&#39;error&#39;, sparse=True) . res = ch_one_hot_enc.transform(df[[&#39;channel&#39;]]).toarray() . for i in range(res.shape[1]): features[f&#39;ch_{i}&#39;] = res.T[0] . features . cash_amount starter_age ch_0 ch_1 ch_2 ch_3 . 0 -0.359936 | -1.247867 | 1.0 | 1.0 | 1.0 | 1.0 | . 1 1.585284 | 1.679835 | 0.0 | 0.0 | 0.0 | 0.0 | . 2 0.514594 | 0.215984 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 0.656062 | -0.306820 | 0.0 | 0.0 | 0.0 | 0.0 | . 4 -0.293420 | 0.320545 | 1.0 | 1.0 | 1.0 | 1.0 | . ... ... | ... | ... | ... | ... | ... | . 20016 0.003829 | -1.143306 | 0.0 | 0.0 | 0.0 | 0.0 | . 20017 1.659959 | -0.202259 | 1.0 | 1.0 | 1.0 | 1.0 | . 20018 0.405623 | 0.111423 | 1.0 | 1.0 | 1.0 | 1.0 | . 20019 0.796009 | 0.843349 | 1.0 | 1.0 | 1.0 | 1.0 | . 20020 0.373402 | -0.306820 | 0.0 | 0.0 | 0.0 | 0.0 | . 20021 rows × 6 columns . OneHot&#65306;starter_area . area_one_hot_enc = preprocessing.OneHotEncoder() area_one_hot_enc.fit(df[[&#39;starter_area&#39;]]) . OneHotEncoder(categories=&#39;auto&#39;, drop=None, dtype=&lt;class &#39;numpy.float64&#39;&gt;, handle_unknown=&#39;error&#39;, sparse=True) . area_one_hot_enc . OneHotEncoder(categories=&#39;auto&#39;, drop=None, dtype=&lt;class &#39;numpy.float64&#39;&gt;, handle_unknown=&#39;error&#39;, sparse=True) . res = area_one_hot_enc.transform(df[[&#39;starter_area&#39;]]).toarray() . for i in range(res.shape[1]): features[f&#39;area_{i}&#39;] = res.T[0] . features . cash_amount starter_age ch_0 ch_1 ch_2 ch_3 area_0 area_1 area_2 area_3 ... area_11 area_12 area_13 area_14 area_15 area_16 area_17 area_18 area_19 area_20 . 0 -0.359936 | -1.247867 | 1.0 | 1.0 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1 1.585284 | 1.679835 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 2 0.514594 | 0.215984 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 0.656062 | -0.306820 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 4 -0.293420 | 0.320545 | 1.0 | 1.0 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 20016 0.003829 | -1.143306 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 20017 1.659959 | -0.202259 | 1.0 | 1.0 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 20018 0.405623 | 0.111423 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | ... | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | . 20019 0.796009 | 0.843349 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | ... | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | . 20020 0.373402 | -0.306820 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 20021 rows × 27 columns . &#38477;&#32500;&#35266;&#23519;&#29305;&#24449;&#30340;&#26377;&#25928;&#24615; . import ipyvolume as ipv . %%time from sklearn.manifold import TSNE tsne = TSNE(n_components=3) res = tsne.fit_transform(features) . CPU times: user 12min 31s, sys: 222 ms, total: 12min 31s Wall time: 1min 29s . df_res = pd.DataFrame(index=features.index) for i in range(3): df_res[i] = _res[:, i] . df_res . 0 1 2 . 0 18.165588 | -19.010647 | 1.458440 | . 1 4.450019 | -1.731154 | -32.102139 | . 2 -14.175321 | 3.815895 | -3.988426 | . 3 -5.928217 | -7.826748 | -10.185696 | . 4 13.656402 | 5.804957 | -2.203535 | . ... ... | ... | ... | . 20016 -4.421280 | -13.237238 | 13.659069 | . 20017 -0.839358 | -8.010888 | -3.395279 | . 20018 12.696962 | 1.771047 | 9.034929 | . 20019 4.095841 | 16.873896 | 3.948498 | . 20020 -6.599446 | -6.259656 | -5.781780 | . 20021 rows × 3 columns . df_res.describe() . 0 1 2 . count 20021.000000 | 20021.000000 | 20021.000000 | . mean 0.329172 | -0.163093 | 0.102560 | . std 13.911817 | 15.107344 | 12.062253 | . min -28.235468 | -34.582352 | -32.145741 | . 25% -10.466891 | -11.949810 | -8.984593 | . 50% 0.032380 | -0.298013 | 1.127379 | . 75% 11.903912 | 10.771826 | 8.706995 | . max 29.233423 | 29.592445 | 28.516783 | . from matplotlib import cm import ipyvolume as ipv colormap = cm.Spectral # _c = [i*3 for i in pd.Categorical(df_res[&#39;id&#39;]).codes] # color = colormap(_c) ipv.quickscatter(df_res[0], df_res[1], df_res[2], size=1) # , marker=&quot;sphere&quot;, color=color[:,:3] . . . Note: 从降维后的结果可以看到：这种方法提取的特征无法区分数据。 . &#22522;&#20110;ID&#20043;&#38388;&#20132;&#26131;&#30340;&#29305;&#24449;&#25552;&#21462; . 在数据从交易信息来看，没有明显的分布差别，所以在这里不予考虑。 . &#22522;&#20110;ID&#30340;&#29305;&#24449;&#25552;&#21462; . 从四个维度来提取： . 发起交易的金额总量和交易数； | 接收交易的金额总量和交易数； | . &#21457;&#36215;&#20132;&#26131;&#30340;&#37329;&#39069;&#24635;&#37327;&#21644;&#20132;&#26131;&#25968; . f = {&#39;cash_amount&#39;: [&#39;count&#39;, &#39;sum&#39;]} starter_df = df.groupby(&#39;starter_id&#39;).aggregate(f) starter_df.columns = [&#39;_&#39;.join(col).strip() for col in starter_df.columns.values] . starter_df.columns = [&#39;s_cash_amount_count&#39;, &#39;s_cash_amount_sum&#39;] . starter_df . s_cash_amount_count s_cash_amount_sum . starter_id . 1 1 | 2764000 | . 2 5 | 18098000 | . 3 3 | 8589800 | . 4 6 | 16682400 | . 5 2 | 5435500 | . ... ... | ... | . 6996 5 | 9014400 | . 6997 3 | 3548100 | . 6998 1 | 2878000 | . 6999 5 | 15088000 | . 7000 3 | 9085800 | . 6583 rows × 2 columns . &#25509;&#25910;&#20132;&#26131;&#30340;&#37329;&#39069;&#24635;&#37327;&#21644;&#20132;&#26131;&#25968; . f = {&#39;cash_amount&#39;: [&#39;count&#39;, &#39;sum&#39;]} receiver_df = df.groupby(&#39;receiver_id&#39;).aggregate(f) receiver_df.columns = [&#39;_&#39;.join(col).strip() for col in receiver_df.columns.values] . receiver_df.columns = [&#39;e_cash_amount_count&#39;, &#39;e_cash_amount_sum&#39;] receiver_df . e_cash_amount_count e_cash_amount_sum . receiver_id . 1 202 | 497892400 | . 2 179 | 457216300 | . 3 201 | 505419500 | . 4 214 | 539274100 | . 5 222 | 562892800 | . ... ... | ... | . 1434 1 | 8888800 | . 3012 1 | 405300 | . 4962 1 | 3279200 | . 5916 1 | 4554200 | . 6258 1 | 2977500 | . 117 rows × 2 columns . features = receiver_df.join(starter_df, how=&#39;outer&#39;) . # 填充NaN features = features.fillna(0) features . e_cash_amount_count e_cash_amount_sum s_cash_amount_count s_cash_amount_sum . 1 202.0 | 497892400.0 | 1.0 | 2764000.0 | . 2 179.0 | 457216300.0 | 5.0 | 18098000.0 | . 3 201.0 | 505419500.0 | 3.0 | 8589800.0 | . 4 214.0 | 539274100.0 | 6.0 | 16682400.0 | . 5 222.0 | 562892800.0 | 2.0 | 5435500.0 | . ... ... | ... | ... | ... | . 6996 0.0 | 0.0 | 5.0 | 9014400.0 | . 6997 0.0 | 0.0 | 3.0 | 3548100.0 | . 6998 0.0 | 0.0 | 1.0 | 2878000.0 | . 6999 0.0 | 0.0 | 5.0 | 15088000.0 | . 7000 0.0 | 0.0 | 3.0 | 9085800.0 | . 6596 rows × 4 columns . &#24402;&#19968;&#21270; . z_score_scaler = preprocessing.StandardScaler() z_score_feature = z_score_scaler.fit_transform(features) . _features = pd.DataFrame(z_score_feature, index=features.index) . _features . 0 1 2 3 . 1 8.122062 | 7.981598 | -1.276431 | -0.988593 | . 2 7.183164 | 7.319397 | 1.232125 | 2.134452 | . 3 8.081240 | 8.104138 | -0.022153 | 0.197936 | . 4 8.611921 | 8.655286 | 1.859264 | 1.846140 | . 5 8.938494 | 9.039796 | -0.649292 | -0.444493 | . ... ... | ... | ... | ... | . 6996 -0.123907 | -0.124019 | 1.232125 | 0.284414 | . 6997 -0.123907 | -0.124019 | -0.022153 | -0.828896 | . 6998 -0.123907 | -0.124019 | -1.276431 | -0.965374 | . 6999 -0.123907 | -0.124019 | 1.232125 | 1.521412 | . 7000 -0.123907 | -0.124019 | -0.022153 | 0.298956 | . 6596 rows × 4 columns . &#38477;&#32500;&#35266;&#23519;&#29305;&#24449;&#26377;&#25928;&#24615; . %%time from sklearn.manifold import TSNE tsne = TSNE(n_components=3) _res = tsne.fit_transform(_features) . CPU times: user 3min 30s, sys: 128 ms, total: 3min 30s Wall time: 25.5 s . df_res = pd.DataFrame(index=_features.index) for i in range(3): df_res[i] = _res[:, i] . df_res.reset_index(inplace=True) . df_res . index 0 1 2 . 0 0 | -2.616519 | 10.399817 | 16.650976 | . 1 1 | 0.269044 | 8.815780 | 21.424440 | . 2 2 | -1.138858 | 9.294405 | 19.571409 | . 3 3 | -0.300031 | 9.371153 | 21.505943 | . 4 4 | -3.027676 | 11.100630 | 18.954000 | . ... ... | ... | ... | ... | . 6591 6591 | 9.084714 | 10.959700 | -5.038331 | . 6592 6592 | -4.531178 | 27.202545 | -1.383322 | . 6593 6593 | -14.335349 | -15.130382 | -5.814716 | . 6594 6594 | 1.527327 | -24.622822 | -3.664261 | . 6595 6595 | -22.862921 | -3.276567 | 5.567962 | . 6596 rows × 4 columns . from matplotlib import cm import ipyvolume as ipv colormap = cm.Spectral # _c = [i*3 for i in pd.Categorical(df_res[&#39;id&#39;]).codes] # color = colormap(_c) ipv.quickscatter(df_res[0], df_res[1], df_res[2], size=1) # , marker=&quot;sphere&quot;, color=color[:,:3] . . . Note: 从降维后的结果可以看到：这种方法提取的特征很容易异常数据。 . &#26500;&#24314;&#27169;&#22411; . 使用下面3种方式构建模型： . K-means； | 谱聚类模型； | 孤立森林Isolation Forest。 | . K-means&#32858;&#31867;&#27169;&#22411; . %%time from sklearn.cluster import KMeans y_pred = KMeans(n_clusters=2, random_state=10).fit_predict(_features) . CPU times: user 200 ms, sys: 318 ms, total: 518 ms Wall time: 46.2 ms . from matplotlib import cm import ipyvolume as ipv df_res = _features.reset_index() # pd.Categorical(y_pred).codes colormap = cm.Spectral _c = [i*100 for i in pd.Categorical(y_pred).codes] color = colormap(_c) ipv.quickscatter(df_res[0], df_res[1], df_res[3], size=2, marker=&quot;sphere&quot;, color=color[:,:3]) . . _df = pd.DataFrame(y_pred, index=_features.index) . _df[_df[0]==1] . 0 . 1 1 | . 2 1 | . 3 1 | . 4 1 | . 5 1 | . ... ... | . 96 1 | . 97 1 | . 98 1 | . 99 1 | . 100 1 | . 100 rows × 1 columns . . Note: 耗时39ms，但效果很差。 . &#35889;&#32858;&#31867;&#27169;&#22411; . %%time from sklearn.cluster import SpectralClustering y_pred = SpectralClustering(n_clusters=2).fit_predict(_features) . CPU times: user 18.3 s, sys: 16.9 s, total: 35.3 s Wall time: 6.46 s . from matplotlib import cm import ipyvolume as ipv df_res = _features.reset_index() # pd.Categorical(y_pred).codes colormap = cm.Spectral _c = [i*100 for i in pd.Categorical(y_pred).codes] color = colormap(_c) ipv.quickscatter(df_res[0], df_res[1], df_res[3], size=2, marker=&quot;sphere&quot;, color=color[:,:3]) . _df = pd.DataFrame(y_pred, index=_features.index) . _df[_df[0]==1] . 0 . 1137 1 | . . . Note: 耗时6.46s，效果很好。 . IsolationForest&#26041;&#27861; . features = _features . %%time import numpy as np import matplotlib.pyplot as plt from sklearn.ensemble import IsolationForest from scipy import stats rng = np.random.RandomState(42) # 构造训练样本 n_samples = features.shape[0] #样本总数 outliers_fraction = 1/n_samples #异常样本比例 clf = IsolationForest(max_samples=n_samples , random_state=rng, contamination=outliers_fraction) # , random_state=rng, contamination=outliers_fraction clf.fit(features) # y_pred_train = clf.predict(X_train) scores_pred = clf.decision_function(features) threshold = stats.scoreatpercentile(scores_pred, 100 * outliers_fraction) #根据训练样本中异常样本比例，得到阈值，用于绘图 . CPU times: user 616 ms, sys: 995 µs, total: 617 ms Wall time: 616 ms . scores_pred . array([0.19802162, 0.08466044, 0.21168621, ..., 0.38757413, 0.38741914, 0.42611375]) . threshold . 5.525365321529252e-17 . _df = pd.DataFrame(scores_pred) . res = _df[_df[0] &lt; threshold] . features.iloc[res.index] . e_cash_amount_count e_cash_amount_sum s_cash_amount_count s_cash_amount_sum . 1137 0.0 | 0.0 | 12.0 | 106665600.0 | . . Note: 效果：耗时616ms，结果准确。 . &#27169;&#22411;&#27604;&#36739; . 从运行结果来看，三种模型里： . K-Means效果最差，其余两种效果很好； | 谱聚类模型性能比较差，运行时间是Isolation Forest模型的6倍。 | . TODO . 降到二维/三维可视化展示聚类效果。 | .",
            "url": "https://donyum.github.io/blog/jupyter/2020/04/18/Ali-Ant_v2_1.html",
            "relUrl": "/jupyter/2020/04/18/Ali-Ant_v2_1.html",
            "date": " • Apr 18, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "docker添加GPU支持",
            "content": "起因 . 安装pytorch的时候发现NVIDIA驱动版本太低，各种不兼容，于是从390（CUDA 8.0）升级到了430（CUDA 10.1），重启后docker挂了，于是重装、各种配置。 . 虽然过程多少有些曲折，但结果是好的——以后再也不用在GPU相关软件上抓耳挠腮了。 . 关于软件版本的选择，已经在MongoDB、werkzeug、mongoengine、pymongo、faiss、pytorch上吃过很多亏了，经验就是： . 驱动、软件版本还是尽可能使用最新稳定版！出问题后才考虑二分法回退测试。 . 遇到的坑 . nvidia-docker安装 . nvidia-docker安装方法 . nvidia-docker WIKI . docker-compose的支持 . –gpus选项不支持 . docker最新版本0.19使用--gpus [all/N]选项可以原生支持GPU资源：docker run --gpus all nvidia/cuda:10.0-base nvidia-smi . 但是docker-compose不支持该选项. . 所以这条路走不通。 . 使用runtime方式 . 测试runtime的方法：docker run --runtime=nvidia nvidia/cuda:10.0-base nvidia-smi . | 添加nvidia runtime： . /etc/docker/daemon.json . { &quot;runtimes&quot;: { &quot;nvidia&quot;: { &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;, &quot;runtimeArgs&quot;: [] } } } . 然后重启服务。 . | docker-compose.yml . 需要注意两点：只有2.3版本支持runtime选项，设置runtime: nvidia。Demo： . $ cat docker-compose.yml version: &#39;2.3&#39; services: nvidia-smi-test: runtime: nvidia image: nvidia/cuda:9.2-runtime-centos7 . | . 参考： . Support for NVIDIA GPUs under Docker Compose | nvidia-container-runtime | .",
            "url": "https://donyum.github.io/blog/markdown/2020/04/17/docker-with-GPU-support.html",
            "relUrl": "/markdown/2020/04/17/docker-with-GPU-support.html",
            "date": " • Apr 17, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://donyum.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://donyum.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". .",
          "url": "https://donyum.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://donyum.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}